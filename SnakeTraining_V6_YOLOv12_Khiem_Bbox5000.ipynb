{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-khiem7/AWS.FirstCloudJourney/blob/main/SnakeTraining_V6_YOLOv12_Khiem_Bbox5000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaGgQiprFPvO"
      },
      "source": [
        "# Environment setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nvidia profile"
      ],
      "metadata": {
        "id": "JbqYzrdr_Bpa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kI_KzJP12XC"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure model name"
      ],
      "metadata": {
        "id": "Lb9xiXaS_J81"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1EREBTtjrgc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "HOME = os.getcwd()\n",
        "print(f\"üìÇ HOME: {HOME}\")\n",
        "\n",
        "PROJECT_NAME = \"SnakeTraining\"\n",
        "VERSION      = \"V6\"\n",
        "MODEL_ARCH   = \"YOLOv12\"\n",
        "AUTHOR       = \"Khiem\"\n",
        "DATA_INFO    = \"Bbox5291Complete\"\n",
        "\n",
        "# L·∫•y th·ªùi gian hi·ªán t·∫°i theo m√∫i gi·ªù UTC+7\n",
        "utc_plus_7 = timezone(timedelta(hours=7))\n",
        "current_time = datetime.now(utc_plus_7).strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "# Gh√©p chu·ªói t√™n model k√®m timestamp\n",
        "notebook_name = f\"{PROJECT_NAME}_{VERSION}_{MODEL_ARCH}_{AUTHOR}_{DATA_INFO}_40epoch_10patience_{current_time}\"\n",
        "\n",
        "print(f\"üìò Configured Model Name: {notebook_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect Google Drive"
      ],
      "metadata": {
        "id": "b3ZTkFFs_NLH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "563dcec6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59ccbf61"
      },
      "source": [
        "### Define Dataset Paths and copy to Colab local Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faba6092"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "from tqdm.notebook import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# --- CONFIG ---\n",
        "DRIVE_DATASET_PATH = '/content/drive/MyDrive/SnakeDataset/SnakeAid-YOLOv12-5291BBox'\n",
        "DATASET_PATH = '/content/snake_dataset'\n",
        "DATA_YAML_PATH = f'{DATASET_PATH}/data.yaml'\n",
        "\n",
        "def check_dataset_integrity(path):\n",
        "    \"\"\"Ki·ªÉm tra th√¥ng minh: Tr·∫£ v·ªÅ True n·∫øu data ƒë√£ ƒë·∫ßy ƒë·ªß\"\"\"\n",
        "    # 1. Check file c·∫•u h√¨nh\n",
        "    if not os.path.exists(f\"{path}/data.yaml\"):\n",
        "        return False\n",
        "\n",
        "    # 2. Check c√°c folder quan tr·ªçng (train, valid, test)\n",
        "    # N·∫øu b·∫•t k·ª≥ folder n√†o thi·∫øu ho·∫∑c r·ªóng -> coi nh∆∞ l·ªói -> copy l·∫°i\n",
        "    required_dirs = [\n",
        "        'train/images', 'train/labels',\n",
        "        'valid/images', 'valid/labels',\n",
        "        'test/images', 'test/labels'\n",
        "    ]\n",
        "\n",
        "    for d in required_dirs:\n",
        "        dir_path = os.path.join(path, d)\n",
        "        if not os.path.exists(dir_path):\n",
        "            return False\n",
        "        if not os.listdir(dir_path): # Folder r·ªóng\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def copy_file_worker(args):\n",
        "    \"\"\"H√†m worker ƒë·ªÉ copy 1 file (d√πng cho ƒëa lu·ªìng)\"\"\"\n",
        "    src, dst = args\n",
        "    try:\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "        shutil.copy2(src, dst)\n",
        "    except Exception as e:\n",
        "        # C√≥ th·ªÉ log error n·∫øu c·∫ßn\n",
        "        pass\n",
        "\n",
        "def fast_copy_multithread(src_root, dst_root, workers=16):\n",
        "    \"\"\"Copy d·ªØ li·ªáu s·ª≠ d·ª•ng ƒëa lu·ªìng ƒë·ªÉ t·ªëi ∆∞u I/O\"\"\"\n",
        "    if os.path.exists(dst_root):\n",
        "        print(f\"üóëÔ∏è Ph√°t hi·ªán d·ªØ li·ªáu kh√¥ng to√†n v·∫πn. ƒêang x√≥a {dst_root}...\")\n",
        "        shutil.rmtree(dst_root)\n",
        "\n",
        "    print(\"üîç ƒêang qu√©t danh s√°ch file ngu·ªìn (Scanning)...\")\n",
        "    files_to_copy = []\n",
        "    for root, dirs, files in os.walk(src_root):\n",
        "        for file in files:\n",
        "            src_file = os.path.join(root, file)\n",
        "            rel_path = os.path.relpath(src_file, src_root)\n",
        "            dst_file = os.path.join(dst_root, rel_path)\n",
        "            files_to_copy.append((src_file, dst_file))\n",
        "\n",
        "    print(f\"üöÄ T√¨m th·∫•y {len(files_to_copy)} files. B·∫Øt ƒë·∫ßu copy t·ªëc ƒë·ªô cao (16 threads)...\")\n",
        "\n",
        "    # ThreadPoolExecutor gi√∫p request nhi·ªÅu file c√πng l√∫c t·ª´ Drive\n",
        "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "        list(tqdm(executor.map(copy_file_worker, files_to_copy), total=len(files_to_copy), unit=\"file\"))\n",
        "\n",
        "# --- MAIN FLOW ---\n",
        "if check_dataset_integrity(DATASET_PATH):\n",
        "    print(\"‚úÖ Smart Check: D·ªØ li·ªáu ƒë√£ ƒë·∫ßy ƒë·ªß v√† h·ª£p l·ªá t·∫°i Local. (Skipped Copy)\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Smart Check: D·ªØ li·ªáu thi·∫øu ho·∫∑c ch∆∞a c√≥. Ti·∫øn h√†nh copy...\")\n",
        "    try:\n",
        "        fast_copy_multithread(DRIVE_DATASET_PATH, DATASET_PATH)\n",
        "\n",
        "        # C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n trong data.yaml\n",
        "        if os.path.exists(DATA_YAML_PATH):\n",
        "            with open(DATA_YAML_PATH, 'r') as f:\n",
        "                data_config = yaml.safe_load(f)\n",
        "\n",
        "            data_config['path'] = DATASET_PATH\n",
        "            # Fix ƒë∆∞·ªùng d·∫´n relative\n",
        "            for key in ['train', 'val', 'test']:\n",
        "                if key in data_config and isinstance(data_config[key], str):\n",
        "                    if 'drive' in data_config[key].lower():\n",
        "                        folder = 'valid' if key == 'val' else key\n",
        "                        data_config[key] = f'{folder}/images'\n",
        "\n",
        "            with open(DATA_YAML_PATH, 'w') as f:\n",
        "                yaml.dump(data_config, f)\n",
        "            print(\"‚úÖ C·∫•u h√¨nh data.yaml ho√†n t·∫•t!\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y data.yaml sau khi copy!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå L·ªói khi copy: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset file validation"
      ],
      "metadata": {
        "id": "ls0MG5Nc_ROM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7808e264"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def check_dataset(root, folders=(\"train\", \"valid\", \"test\")):\n",
        "    table = Table(\n",
        "        title=\"Dataset Structure\",\n",
        "        box=box.SIMPLE_HEAD,\n",
        "        show_lines=False,\n",
        "        pad_edge=False\n",
        "    )\n",
        "\n",
        "    table.add_column(\"Component\", style=\"bold cyan\", justify=\"center\")\n",
        "    table.add_column(\"Status/Images\", justify=\"center\")\n",
        "    table.add_column(\"Labels\", justify=\"center\")\n",
        "\n",
        "    missing_files = False\n",
        "\n",
        "    yaml_path = os.path.join(root, \"data.yaml\")\n",
        "    yaml_exists = os.path.exists(yaml_path)\n",
        "\n",
        "    if not yaml_exists:\n",
        "        missing_files = True\n",
        "\n",
        "    table.add_row(\n",
        "        \"data.yaml\",\n",
        "        \"[green]FOUND\" if yaml_exists else \"[red]MISSING\",\n",
        "        \"-\"\n",
        "    )\n",
        "\n",
        "    for folder in folders:\n",
        "        fp = os.path.join(root, folder)\n",
        "        img = os.path.join(fp, \"images\")\n",
        "        lbl = os.path.join(fp, \"labels\")\n",
        "\n",
        "        img_exists = os.path.exists(img)\n",
        "        lbl_exists = os.path.exists(lbl)\n",
        "\n",
        "        if not img_exists or not lbl_exists:\n",
        "            missing_files = True\n",
        "\n",
        "        table.add_row(\n",
        "            folder.upper(),\n",
        "            \"[green]FOUND\" if img_exists else \"[red]MISSING\",\n",
        "            \"[green]FOUND\" if lbl_exists else \"[red]MISSING\",\n",
        "        )\n",
        "\n",
        "    panel = Panel.fit(\n",
        "        table,\n",
        "        title=\"üêç Snake Dataset Check\",\n",
        "        border_style=\"cyan\",\n",
        "        box=box.SIMPLE\n",
        "    )\n",
        "\n",
        "    print(panel)\n",
        "\n",
        "    if missing_files:\n",
        "        raise FileNotFoundError(\"Dataset structure is incomplete! Please check your dataset path and structure.\")\n",
        "\n",
        "check_dataset(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label distribution per class"
      ],
      "metadata": {
        "id": "RJtx-EiB_eSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# --- 1. Load Class Names from data.yaml ---\n",
        "with open(DATA_YAML_PATH, 'r') as f:\n",
        "    data_cfg = yaml.safe_load(f)\n",
        "\n",
        "# Handle 'names' format (dict or list)\n",
        "if isinstance(data_cfg['names'], dict):\n",
        "    id2name = data_cfg['names']\n",
        "else:\n",
        "    id2name = {i: name for i, name in enumerate(data_cfg['names'])}\n",
        "\n",
        "# --- 2. Count Objects per Class ---\n",
        "# Qu√©t t·∫•t c·∫£ file nh√£n trong train, valid, test\n",
        "label_files = []\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    path = os.path.join(DATASET_PATH, split, 'labels')\n",
        "    if os.path.exists(path):\n",
        "        label_files.extend(glob.glob(os.path.join(path, \"*.txt\")))\n",
        "\n",
        "print(f\"üîç Found {len(label_files)} label files in {DATASET_PATH}\")\n",
        "\n",
        "cls_counts = Counter()\n",
        "for lf in tqdm(label_files, desc=\"Counting labels\"):\n",
        "    with open(lf, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if parts:\n",
        "                cls_id = int(parts[0])\n",
        "                cls_counts[cls_id] += 1\n",
        "\n",
        "# --- 3. Prepare Data for Plotting ---\n",
        "data = []\n",
        "# Sort by Class ID to ensure consistent order\n",
        "for cid in sorted(id2name.keys()):\n",
        "    cname = id2name[cid]\n",
        "    cnt = cls_counts.get(cid, 0)\n",
        "    data.append((cname, cnt))\n",
        "\n",
        "# Unpack\n",
        "class_names, class_counts = zip(*data)\n",
        "\n",
        "# --- 4. Plotting (Adapted from Template) ---\n",
        "plt.figure(figsize=(20, 10))  # TƒÉng chi·ªÅu cao m·ªôt ch√∫t\n",
        "bars = plt.bar(class_names, class_counts, color='skyblue', edgecolor='navy', alpha=0.8)\n",
        "\n",
        "# TƒÉng fontsize cho xticks (t√™n class)\n",
        "plt.xticks(rotation=90, ha=\"center\", fontsize=14)\n",
        "plt.xlabel(\"Snake Class\", fontsize=14, fontweight='bold')\n",
        "plt.ylabel(\"Number of Labels (Objects)\", fontsize=14, fontweight='bold')\n",
        "plt.title(f\"Label Distribution per Snake Class (Total: {sum(class_counts)})\", fontsize=16, fontweight='bold')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Ghi s·ªë l√™n ƒë·∫ßu c·ªôt\n",
        "max_h = max(class_counts) if class_counts else 0\n",
        "for bar in bars:\n",
        "    h = bar.get_height()\n",
        "    if h > 0:\n",
        "        plt.text(\n",
        "            bar.get_x() + bar.get_width() / 2,\n",
        "            h + (max_h * 0.01),\n",
        "            str(int(h)),\n",
        "            ha=\"center\",\n",
        "            va=\"bottom\",\n",
        "            fontsize=12,\n",
        "            rotation=90 if len(class_names) > 30 else 0\n",
        "        )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RKpvgnVE_ht_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54fd13ea"
      },
      "source": [
        "# Install YOLOv12 and SuperVision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4HSbchh19MH"
      },
      "source": [
        "## Install essential python package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8JKctYYXV3tv",
        "outputId": "941cd3f1-0d04-4d0b-d3d3-573f58fa4113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/sunsmarterjie/yolov12.git supervision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "print(ultralytics.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAlz86tSLhm0",
        "outputId": "b88625dd-f059-4d8f-fb17-273b155fe241"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.3.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGUoLporEfTs"
      },
      "source": [
        "# Test the base models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P579Wz8j8dM"
      },
      "source": [
        "### Download example data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWKaiK4AWycO"
      },
      "outputs": [],
      "source": [
        "!wget https://media.roboflow.com/notebooks/examples/dog.jpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTntULfj-ly"
      },
      "source": [
        "### Run inference\n",
        "\n",
        "In the example, we're using the `yolov12l.pt` model, but you can experiment with different model sizes by simply swapping out the model name during initialization. Options include `yolov12n.pt`, `yolov12s.pt`, `yolov12m.pt`, `yolov12l.pt`, and `yolov12x.pt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFOfDnL_Ia8Y"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "\n",
        "\n",
        "image_path = f\"{HOME}/dog.jpeg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "model = YOLO('yolov12l.pt')\n",
        "\n",
        "results = model(image, verbose=False)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONOK84CITP50"
      },
      "source": [
        "# Fine-tune YOLOv12 model\n",
        "\n",
        "We are now ready to fine-tune our YOLOv12 model. In the code below, we initialize the model using a starting checkpoint‚Äîhere, we use `yolov12s.yaml`, but you can replace it with any other model (e.g., `yolov12n.pt`, `yolov12m.pt`, `yolov12l.pt`, or `yolov12x.pt`) based on your preference. We set the training to run for 100 epochs in this example; however, you should adjust the number of epochs along with other hyperparameters such as batch size, image size, and augmentation settings (scale, mosaic, mixup, and copy-paste) based on your hardware capabilities and dataset size.\n",
        "\n",
        "**Note:** **Note that after training, you might encounter a `TypeError: argument of type 'PosixPath' is not iterable error` ‚Äî this is a known issue, but your model weights will still be saved, so you can safely proceed to running inference.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YBjWLSSQ_n1"
      },
      "outputs": [],
      "source": [
        "# from ultralytics import YOLO\n",
        "\n",
        "# model = YOLO('yolov12m.pt')\n",
        "# results = model.train(data=DATA_YAML_PATH, epochs=100, patience=10, cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU detect"
      ],
      "metadata": {
        "id": "Hb-OaMV2Ksv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "A8lZy0qpUkh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from rich import print\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "from rich import box"
      ],
      "metadata": {
        "id": "tme1FCMuKueQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helpers + Rich logger**"
      ],
      "metadata": {
        "id": "gYwmI5BJUrNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_kaggle_env() -> bool:\n",
        "    # Kaggle notebooks always set this\n",
        "    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
        "\n",
        "def log_gpu_info():\n",
        "    table = Table(\n",
        "        title=\"GPU Runtime Information\",\n",
        "        box=box.SIMPLE_HEAVY,\n",
        "        show_header=True,\n",
        "        header_style=\"bold cyan\"\n",
        "    )\n",
        "    table.add_column(\"Metric\", style=\"bold\")\n",
        "    table.add_column(\"Value\")\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        table.add_row(\"CUDA Available\", \"‚ùå No\")\n",
        "        table.add_row(\"GPU Count\", \"0\")\n",
        "        print(table)\n",
        "        return\n",
        "\n",
        "    idx = torch.cuda.current_device()\n",
        "    props = torch.cuda.get_device_properties(idx)\n",
        "\n",
        "    total_gb = props.total_memory / (1024**3)\n",
        "    reserved_gb = torch.cuda.memory_reserved(idx) / (1024**3)\n",
        "    allocated_gb = torch.cuda.memory_allocated(idx) / (1024**3)\n",
        "    free_gb = total_gb - reserved_gb\n",
        "\n",
        "    table.add_row(\"CUDA Available\", \"‚úÖ Yes\")\n",
        "    table.add_row(\"GPU Name\", props.name)\n",
        "    table.add_row(\"GPU Count\", str(torch.cuda.device_count()))\n",
        "    table.add_row(\"VRAM Total\", f\"{total_gb:.2f} GB\")\n",
        "    table.add_row(\"VRAM Reserved\", f\"{reserved_gb:.2f} GB\")\n",
        "    table.add_row(\"VRAM Allocated\", f\"{allocated_gb:.2f} GB\")\n",
        "    table.add_row(\"VRAM Free (approx)\", f\"{free_gb:.2f} GB\")\n",
        "\n",
        "    print(table)"
      ],
      "metadata": {
        "id": "oEvGSZGkUq_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main detection (select profile)**"
      ],
      "metadata": {
        "id": "zAjKy0kZUvW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_training_profile():\n",
        "    kaggle = is_kaggle_env()\n",
        "\n",
        "    env_name = \"Kaggle\" if kaggle else \"Colab / Other\"\n",
        "    print(\n",
        "        Panel.fit(\n",
        "            f\"[bold]Environment:[/bold] {env_name}\",\n",
        "            title=\"Runtime Environment\",\n",
        "            border_style=\"green\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Log GPU info (log only)\n",
        "    log_gpu_info()\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        return \"CPU\"\n",
        "\n",
        "    gpu_name = torch.cuda.get_device_name(0).lower()\n",
        "\n",
        "    # Kaggle mapping\n",
        "    if kaggle:\n",
        "        if \"p100\" in gpu_name:\n",
        "            return \"KAGGLE_P100\"\n",
        "        if \"t4\" in gpu_name:\n",
        "            return \"KAGGLE_T4X2\"\n",
        "        return \"KAGGLE_P100\"\n",
        "\n",
        "    # Colab mapping\n",
        "    if \"a100\" in gpu_name:\n",
        "        return \"A100\"\n",
        "    if \"l4\" in gpu_name:\n",
        "        return \"L4\"\n",
        "    if \"t4\" in gpu_name:\n",
        "        return \"T4\"\n",
        "\n",
        "    return \"T4\"\n",
        "\n",
        "\n",
        "TRAIN_PROFILE = select_training_profile()\n",
        "\n",
        "print(\n",
        "    Panel.fit(\n",
        "        f\"[bold cyan]Selected training profile:[/bold cyan] [bold yellow]{TRAIN_PROFILE}[/bold yellow]\",\n",
        "        title=\"Profile Selection\",\n",
        "        border_style=\"cyan\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "Mo_Nf_zOUwEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training profiles\n",
        "\n",
        "**`epochs=200`**\n",
        "\n",
        "* **Ch·ª©c nƒÉng:** X√°c ƒë·ªãnh s·ªë v√≤ng l·∫∑p hu·∫•n luy·ªán t·ªëi ƒëa m√† m√¥ h√¨nh s·∫Ω ch·∫°y tr√™n to√†n b·ªô t·∫≠p d·ªØ li·ªáu.\n",
        "* **L√Ω do l·ª±a ch·ªçn:** V·ªõi ƒë·ªëi t∆∞·ª£ng r·∫Øn th∆∞·ªùng nh·ªè v√† kh√≥ ph√¢n bi·ªát v·ªõi n·ªÅn, c√°c ch·ªâ s·ªë nh∆∞ mAP v√† Recall th∆∞·ªùng c·∫£i thi·ªán mu·ªôn, v√¨ v·∫≠y c·∫ßn nhi·ªÅu epoch h∆°n m·ª©c m·∫∑c ƒë·ªãnh (100) ƒë·ªÉ m√¥ h√¨nh h·ªôi t·ª• ƒë·∫ßy ƒë·ªß.\n",
        "\n",
        "---\n",
        "\n",
        "**`patience=40`**\n",
        "\n",
        "* **Ch·ª©c nƒÉng:** ƒêi·ªÅu khi·ªÉn c∆° ch·∫ø early stopping, m√¥ h√¨nh s·∫Ω d·ª´ng hu·∫•n luy·ªán n·∫øu metric validation kh√¥ng c·∫£i thi·ªán sau s·ªë epoch n√†y.\n",
        "* **L√Ω do l·ª±a ch·ªçn:** Trong b√†i to√°n SnakeAid, metric th∆∞·ªùng dao ƒë·ªông m·∫°nh do v·∫≠t th·ªÉ nh·ªè v√† n·ªÅn ph·ª©c t·∫°p, n√™n ƒë·∫∑t patience cao ƒë·ªÉ tr√°nh d·ª´ng hu·∫•n luy·ªán qu√° s·ªõm khi m√¥ h√¨nh ch∆∞a ƒë·∫°t tr·∫°ng th√°i t·ªëi ∆∞u.\n",
        "\n",
        "---\n",
        "\n",
        "**`imgsz=896`**\n",
        "\n",
        "* **Ch·ª©c nƒÉng:** Thi·∫øt l·∫≠p ƒë·ªô ph√¢n gi·∫£i ·∫£nh ƒë·∫ßu v√†o cho qu√° tr√¨nh hu·∫•n luy·ªán.\n",
        "* **L√Ω do l·ª±a ch·ªçn:** R·∫Øn trong ·∫£nh th∆∞·ªùng chi·∫øm r·∫•t √≠t pixel, tƒÉng ƒë·ªô ph√¢n gi·∫£i gi√∫p m√¥ h√¨nh gi·ªØ l·∫°i nhi·ªÅu chi ti·∫øt kh√¥ng gian h∆°n, t·ª´ ƒë√≥ c·∫£i thi·ªán kh·∫£ nƒÉng ph√°t hi·ªán r·∫Øn nh·ªè ho·∫∑c ·ªü xa.\n",
        "\n",
        "---\n",
        "\n",
        "**`batch=16`**\n",
        "\n",
        "* **Ch·ª©c nƒÉng:** X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng ·∫£nh ƒë∆∞·ª£c x·ª≠ l√Ω trong m·ªôt b∆∞·ªõc c·∫≠p nh·∫≠t gradient.\n",
        "* **L√Ω do l·ª±a ch·ªçn:** Batch size v·ª´a ph·∫£i gi√∫p c√¢n b·∫±ng gi·ªØa ƒë·ªô ·ªïn ƒë·ªãnh c·ªßa gradient v√† kh·∫£ nƒÉng h·ªçc c√°c v·∫≠t th·ªÉ nh·ªè, tr√°nh hi·ªán t∆∞·ª£ng l√†m m∆∞·ª£t qu√° m·ª©c khi batch qu√° l·ªõn.\n",
        "\n",
        "---\n",
        "\n",
        "**`cache=True`**\n",
        "\n",
        "* **Ch·ª©c nƒÉng:** L∆∞u d·ªØ li·ªáu hu·∫•n luy·ªán v√†o b·ªô nh·ªõ ƒë·ªám ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô ƒë·ªçc d·ªØ li·ªáu.\n",
        "* **L√Ω do l·ª±a ch·ªçn:** Dataset ƒë∆∞·ª£c l∆∞u tr√™n Google Drive khi train b·∫±ng Colab, vi·ªác b·∫≠t cache gi√∫p gi·∫£m ƒë·ªô tr·ªÖ I/O v√† r√∫t ng·∫Øn th·ªùi gian hu·∫•n luy·ªán t·ªïng th·ªÉ.\n",
        "\n",
        "---\n",
        "\n",
        "**`workers=8`**\n",
        "\n",
        "* **Ch·ª©c nƒÉng:** X√°c ƒë·ªãnh s·ªë ti·∫øn tr√¨nh CPU song song ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë·ªçc d·ªØ li·ªáu, ti·ªÅn x·ª≠ l√Ω ·∫£nh v√† √°p d·ª•ng c√°c augmentation tr∆∞·ªõc khi d·ªØ li·ªáu ƒë∆∞·ª£c ƒë∆∞a v√†o GPU trong qu√° tr√¨nh hu·∫•n luy·ªán.\n",
        "* **L√Ω do l·ª±a ch·ªçn:** V·ªõi ·∫£nh ƒë·ªô ph√¢n gi·∫£i cao (`imgsz=896`) v√† d·ªØ li·ªáu l∆∞u tr√™n Google Drive khi hu·∫•n luy·ªán b·∫±ng Colab A100, vi·ªác s·ª≠ d·ª•ng `workers=8` gi√∫p t·∫≠n d·ª•ng hi·ªáu qu·∫£ t√†i nguy√™n CPU, tr√°nh t√¨nh tr·∫°ng GPU ph·∫£i ch·ªù d·ªØ li·ªáu v√† ƒë·∫£m b·∫£o t·ªëc ƒë·ªô hu·∫•n luy·ªán ·ªïn ƒë·ªãnh cho b√†i to√°n nh·∫≠n di·ªán r·∫Øn nh·ªè v√† ·ªü xa.\n",
        "\n",
        "---\n",
        "\n",
        "**`cos_lr=True`**\n",
        "\n",
        "* **Ch·ª©c nƒÉng:** S·ª≠ d·ª•ng chi·∫øn l∆∞·ª£c gi·∫£m learning rate theo h√†m cosine trong qu√° tr√¨nh hu·∫•n luy·ªán.\n",
        "* **L√Ω do l·ª±a ch·ªçn:** Cosine learning rate gi√∫p fine-tune m∆∞·ª£t h∆°n ·ªü c√°c epoch sau, gi·∫£m nguy c∆° dao ƒë·ªông m·∫°nh v√† gi√∫p m√¥ h√¨nh ·ªïn ƒë·ªãnh khi t·ªëi ∆∞u cho c√°c v·∫≠t th·ªÉ nh·ªè."
      ],
      "metadata": {
        "id": "74RuP2kuVXFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIGS = {\n",
        "\n",
        "    # Quick sanity / pipeline check\n",
        "    \"DEBUG\": dict(\n",
        "        epochs=1,\n",
        "        patience=0,\n",
        "        imgsz=512,\n",
        "        batch=2,\n",
        "        nbs=1,\n",
        "        cache=False,\n",
        "        workers=1,\n",
        "    ),\n",
        "\n",
        "    # CPU-only\n",
        "    \"CPU\": dict(\n",
        "        epochs=120,\n",
        "        patience=30,\n",
        "        imgsz=640,\n",
        "        batch=2,\n",
        "        nbs=8,     # effective batch = 8\n",
        "        cache=\"disk\",\n",
        "        workers=2,\n",
        "    ),\n",
        "\n",
        "    # Colab Free (Tesla T4 16GB VRAM)\n",
        "    \"T4\": dict(\n",
        "        epochs=80,\n",
        "        patience=20,\n",
        "        imgsz=768,\n",
        "        batch=4,\n",
        "        nbs=8,     # effective batch = 8\n",
        "        cache=\"disk\",\n",
        "        workers=2,\n",
        "    ),\n",
        "\n",
        "    # Kaggle GPU P100 (16GB VRAM)\n",
        "    \"KAGGLE_P100\": dict(\n",
        "        epochs=80,\n",
        "        patience=20,\n",
        "        imgsz=768,\n",
        "        batch=4,\n",
        "        nbs=8,     # effective batch = 8\n",
        "        cache=\"disk\",\n",
        "        workers=2,\n",
        "    ),\n",
        "\n",
        "    # Kaggle GPU T4 x2 (treated as single T4 unless DDP enabled)\n",
        "    \"KAGGLE_T4X2\": dict(\n",
        "        epochs=80,\n",
        "        patience=20,\n",
        "        imgsz=768,\n",
        "        batch=4,\n",
        "        nbs=8,     # effective batch = 8\n",
        "        cache=\"disk\",\n",
        "        workers=2,\n",
        "    ),\n",
        "\n",
        "    # Colab Pro (NVIDIA L4 24GB VRAM)\n",
        "    \"L4\": dict(\n",
        "        epochs=60,\n",
        "        patience=12,\n",
        "        imgsz=896,\n",
        "        # batch=8,\n",
        "        batch=10,\n",
        "        nbs=16,\n",
        "        cache=True,\n",
        "        workers=6,\n",
        "    ),\n",
        "\n",
        "    # Colab Pro (A100 40GB VRAM)\n",
        "    \"A100\": dict(\n",
        "        epochs=200,\n",
        "        patience=40,\n",
        "        imgsz=896,\n",
        "        batch=16,\n",
        "        nbs=16,\n",
        "        cache=True,\n",
        "        workers=8,\n",
        "    ),\n",
        "}\n",
        "\n",
        "cfg = CONFIGS[TRAIN_PROFILE]\n",
        "\n",
        "print(\"üß† Loaded training configuration:\")\n",
        "for k, v in cfg.items():\n",
        "    print(f\"  {k}: {v}\")"
      ],
      "metadata": {
        "id": "0VC7jht8KxOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM9WZ7AoSmvs"
      },
      "source": [
        "## MAIN TRAIN RUNNER\n",
        "\n",
        "#### `mixup=0.0`\n",
        "\n",
        "* **Ch·ª©c nƒÉng:** ƒêi·ªÅu ch·ªânh m·ª©c ƒë·ªô s·ª≠ d·ª•ng augmentation mixup (tr·ªôn hai ·∫£nh v√† nh√£n).\n",
        "* **L√Ω do l·ª±a ch·ªçn:** Mixup c√≥ th·ªÉ t·∫°o ra c√°c h√¨nh ·∫£nh kh√¥ng th·ª±c t·∫ø ƒë·ªëi v·ªõi ƒë·ªëi t∆∞·ª£ng d√†i v√† m·∫£nh nh∆∞ r·∫Øn, l√†m gi·∫£m ch·∫•t l∆∞·ª£ng h·ªçc, v√¨ v·∫≠y ƒë∆∞·ª£c t·∫Øt ho√†n to√†n trong b√†i to√°n n√†y.\n",
        "\n",
        "---\n",
        "\n",
        "#### `copy_paste=0.0`\n",
        "\n",
        "* **Ch·ª©c nƒÉng:** ƒêi·ªÅu khi·ªÉn augmentation copy-paste, trong ƒë√≥ ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c c·∫Øt v√† d√°n sang ·∫£nh kh√°c.\n",
        "* **L√Ω do l·ª±a ch·ªçn:** Copy-paste c√≥ th·ªÉ t·∫°o ra c√°c v·ªã tr√≠ r·∫Øn kh√¥ng t·ª± nhi√™n trong ·∫£nh, g√¢y nhi·ªÖu cho m√¥ h√¨nh, n√™n ƒë∆∞·ª£c t·∫Øt ƒë·ªÉ gi·ªØ t√≠nh th·ª±c t·∫ø c·ªßa d·ªØ li·ªáu hu·∫•n luy·ªán."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2Zk0Wk5Smg4"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load pretrained model\n",
        "model = YOLO(\"yolov12m.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=(DATA_YAML_PATH),\n",
        "    project=f\"{HOME}/runs/detect\",\n",
        "    name='train',\n",
        "    exist_ok=True,\n",
        "\n",
        "    # epochs=cfg[\"epochs\"],\n",
        "    # patience=cfg[\"patience\"],\n",
        "    epochs=40,\n",
        "    patience=10,\n",
        "    imgsz=cfg[\"imgsz\"],\n",
        "    batch=cfg[\"batch\"],\n",
        "    # nbs=cfg[\"nbs\"],\n",
        "    cache=cfg[\"cache\"],\n",
        "    workers=cfg[\"workers\"],\n",
        "    cos_lr=True,\n",
        "\n",
        "    # Snake-specific augmentation control\n",
        "    mixup=0.0,\n",
        "    copy_paste=0.0,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Training finished\")\n",
        "print(f\"üìÅ Weights saved to: runs/detect/train/weights/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_WJBGEeXRcE"
      },
      "source": [
        "## Save model file into google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df00f760"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source path of the best trained model\n",
        "source_path = f'{HOME}/runs/detect/train/weights/best.pt'\n",
        "\n",
        "# Define the destination directory in Google Drive\n",
        "destination_dir = '/content/drive/MyDrive/SnakeAIModels'\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "# S·ª≠ d·ª•ng bi·∫øn 'notebook_name' ƒë√£ ƒë∆∞·ª£c define ·ªü cell Setup ƒë·∫ßu notebook\n",
        "print(f\"üíæ Saving model for notebook: {notebook_name}\")\n",
        "destination_filename = f\"{notebook_name}.pt\"\n",
        "destination_path = os.path.join(destination_dir, destination_filename)\n",
        "\n",
        "# Copy the model file to Google Drive\n",
        "if os.path.exists(source_path):\n",
        "    shutil.copy(source_path, destination_path)\n",
        "    print(f\"‚úÖ Trained model saved to: {destination_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå Source model not found at {source_path}. Make sure training has finished successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMhVugreT5A5"
      },
      "source": [
        "# Train Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "387eb67d"
      },
      "source": [
        "### Inspect Training Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm1FRMzDTYoR"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!ls {HOME}/runs/detect/train/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97fb1f6f"
      },
      "source": [
        "### Display Training Results Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9y8zJ8nlBUT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/results.png', width=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8f570b2"
      },
      "source": [
        "### Display Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W8FDBVZbRdo"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix_normalized.png', width=1000)"
      ],
      "metadata": {
        "id": "xxJyHhX-zGEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb640378"
      },
      "source": [
        "### Load Test Dataset and Display Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2KT2JlGVS_-"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "ds = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f\"{DATASET_PATH}/test/images\",\n",
        "    annotations_directory_path=f\"{DATASET_PATH}/test/labels\",\n",
        "    data_yaml_path=DATA_YAML_PATH\n",
        ")\n",
        "\n",
        "ds.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c65a7126"
      },
      "source": [
        "### Calculate Mean Average Precision (mAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBZCaDvZWpHc"
      },
      "outputs": [],
      "source": [
        "from supervision.metrics import MeanAveragePrecision\n",
        "\n",
        "model = YOLO(f'{HOME}/runs/detect/train/weights/best.pt')\n",
        "\n",
        "predictions = []\n",
        "targets = []\n",
        "\n",
        "for _, image, target in ds:\n",
        "    results = model(image, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "    predictions.append(detections)\n",
        "    targets.append(target)\n",
        "\n",
        "map = MeanAveragePrecision().update(predictions, targets).compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U9bcrjBXPT2"
      },
      "outputs": [],
      "source": [
        "print(\"mAP 50:95\", map.map50_95)\n",
        "print(\"mAP 50\", map.map50)\n",
        "print(\"mAP 75\", map.map75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmD1SFofXf_o"
      },
      "outputs": [],
      "source": [
        "map.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Qualitative Analysis (Ground Truth vs Predictions)\n",
        "\n",
        "C√°c h√¨nh ·∫£nh n√†y cung c·∫•p b·∫±ng ch·ª©ng tr·ª±c quan v·ªÅ kh·∫£ nƒÉng ƒë·ªãnh v·ªã v√† ph√°t hi·ªán r·∫Øn c·ªßa m√¥ h√¨nh tr√™n t·∫≠p validation.\n",
        "\n",
        "Vi·ªác so s√°nh tr·ª±c ti·∫øp gi·ªØa ground truth v√† prediction gi√∫p:\n",
        "\n",
        "* ƒê√°nh gi√° ƒë·ªô ch√≠nh x√°c c·ªßa bounding box\n",
        "* Quan s√°t c√°c tr∆∞·ªùng h·ª£p false positive v√† false negative\n",
        "* Ki·ªÉm tra hi·ªáu qu·∫£ c·ªßa m√¥ h√¨nh trong c√°c b·ªëi c·∫£nh kh√≥ nh∆∞ r·∫Øn nh·ªè, xa ho·∫∑c l·∫´n n·ªÅn\n",
        "\n",
        "Ph√¢n t√≠ch ƒë·ªãnh t√≠nh n√†y b·ªï sung cho c√°c metric ƒë·ªãnh l∆∞·ª£ng, gi√∫p tƒÉng ƒë·ªô tin c·∫≠y c·ªßa k·∫øt qu·∫£ ƒë√°nh gi√°."
      ],
      "metadata": {
        "id": "GdjpKj3Q0j99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def show_val_batch(batch_id: int):\n",
        "    \"\"\"\n",
        "    Display Ground Truth vs Prediction for a given validation batch.\n",
        "    Batch index is 0-based (e.g., batch_id=0 ‚Üí val_batch0_*).\n",
        "    \"\"\"\n",
        "    gt_path = f\"{HOME}/runs/detect/train/val_batch{batch_id}_labels.jpg\"\n",
        "    pred_path = f\"{HOME}/runs/detect/train/val_batch{batch_id}_pred.jpg\"\n",
        "\n",
        "    gt = Image.open(gt_path)\n",
        "    pred = Image.open(pred_path)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    axes[0].imshow(gt)\n",
        "    axes[0].set_title(f\"Ground Truth Annotations (Batch{batch_id})\", fontsize=12)\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(pred)\n",
        "    axes[1].set_title(f\"Model Predictions (Batch{batch_id})\", fontsize=12)\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xeblQsdg0m8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_val_batch(BATCH_HEAD)"
      ],
      "metadata": {
        "id": "An4JMdkJ--D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_val_batch(BATCH_MID)"
      ],
      "metadata": {
        "id": "-2Zdsf-TAXBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_val_batch(BATCH_TAIL)"
      ],
      "metadata": {
        "id": "CiMYQDtsAYo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Batch Visualization\n",
        "\n",
        "C√°c h√¨nh ·∫£nh batch trong qu√° tr√¨nh hu·∫•n luy·ªán ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ki·ªÉm tra tr·ª±c quan ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu v√† t√≠nh h·ª£p l·ªá c·ªßa annotation.\n",
        "\n",
        "Th√¥ng qua c√°c batch m·∫´u, c√≥ th·ªÉ quan s√°t:\n",
        "\n",
        "* S·ª± ch√≠nh x√°c c·ªßa bounding box so v·ªõi ƒë·ªëi t∆∞·ª£ng th·ª±c t·∫ø\n",
        "* Kh·∫£ nƒÉng bi·ªÉu di·ªÖn c√°c tr∆∞·ªùng h·ª£p kh√≥ nh∆∞ r·∫Øn nh·ªè, xa ho·∫∑c l·∫´n n·ªÅn ph·ª©c t·∫°p\n",
        "* ·∫¢nh h∆∞·ªüng c·ªßa c√°c k·ªπ thu·∫≠t augmentation ƒë·∫øn h√¨nh d·∫°ng v√† ng·ªØ c·∫£nh c·ªßa ƒë·ªëi t∆∞·ª£ng\n",
        "\n",
        "C√°c batch ·ªü giai ƒëo·∫°n ƒë·∫ßu v√† giai ƒëo·∫°n mu·ªôn c·ªßa hu·∫•n luy·ªán ƒë∆∞·ª£c tr√¨nh b√†y nh·∫±m x√°c nh·∫≠n r·∫±ng d·ªØ li·ªáu ƒë·∫ßu v√†o lu√¥n gi·ªØ ƒë∆∞·ª£c t√≠nh nh·∫•t qu√°n v√† ph√π h·ª£p trong su·ªët qu√° tr√¨nh training, g√≥p ph·∫ßn ƒë·∫£m b·∫£o ƒë·ªô tin c·∫≠y c·ªßa k·∫øt qu·∫£ m√¥ h√¨nh."
      ],
      "metadata": {
        "id": "9q4MuLhs5ec8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "batch_imgs = sorted(\n",
        "    glob.glob(f\"{HOME}/runs/detect/train/train_batch*.jpg\")\n",
        ")\n",
        "\n",
        "if len(batch_imgs) >= 4:\n",
        "    selected = [\n",
        "        batch_imgs[0],\n",
        "        batch_imgs[1],\n",
        "        batch_imgs[len(batch_imgs)//2],\n",
        "        batch_imgs[-1],\n",
        "    ]\n",
        "else:\n",
        "    selected = batch_imgs\n",
        "\n",
        "imgs = [Image.open(p) for p in selected]\n",
        "titles = [os.path.basename(p) for p in selected]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, img, title in zip(axes, imgs, titles):\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(title, fontsize=10)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "for ax in axes[len(imgs):]:\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vBme93985eyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confidence-Based Metric Curves\n",
        "\n",
        "B·ªën ƒë∆∞·ªùng cong n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√¢n t√≠ch h√†nh vi c·ªßa m√¥ h√¨nh theo c√°c ng∆∞·ª°ng confidence kh√°c nhau, cung c·∫•p c√°i nh√¨n to√†n di·ªán v·ªÅ ch·∫•t l∆∞·ª£ng d·ª± ƒëo√°n v√† kh·∫£ nƒÉng c√¢n b·∫±ng gi·ªØa ƒë·ªô ch√≠nh x√°c v√† ƒë·ªô bao ph·ªß.\n",
        "\n",
        "* **Precision vs Confidence** cho th·∫•y m·ª©c ƒë·ªô tin c·∫≠y c·ªßa c√°c d·ª± ƒëo√°n khi ng∆∞·ª°ng confidence tƒÉng, ph·∫£n √°nh kh·∫£ nƒÉng ki·ªÉm so√°t false positives c·ªßa m√¥ h√¨nh.\n",
        "* **Recall vs Confidence** th·ªÉ hi·ªán kh·∫£ nƒÉng ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng khi thay ƒë·ªïi ng∆∞·ª°ng confidence, ƒë·∫∑c bi·ªát quan tr·ªçng ƒë·ªëi v·ªõi c√°c ƒë·ªëi t∆∞·ª£ng nh·ªè v√† kh√≥ nh·∫≠n di·ªán nh∆∞ r·∫Øn.\n",
        "* **Precision‚ÄìRecall Curve** m√¥ t·∫£ m·ªëi quan h·ªá ƒë√°nh ƒë·ªïi gi·ªØa Precision v√† Recall tr√™n to√†n b·ªô d·∫£i ng∆∞·ª°ng, gi√∫p ƒë√°nh gi√° t·ªïng th·ªÉ hi·ªáu nƒÉng ph√°t hi·ªán.\n",
        "* **F1 Score vs Confidence** cung c·∫•p ti√™u ch√≠ c√¢n b·∫±ng gi·ªØa Precision v√† Recall, h·ªó tr·ª£ l·ª±a ch·ªçn ng∆∞·ª°ng confidence t·ªëi ∆∞u cho tri·ªÉn khai th·ª±c t·∫ø."
      ],
      "metadata": {
        "id": "pktCITz91zfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "p = Image.open(f\"{HOME}/runs/detect/train/P_curve.png\")\n",
        "r = Image.open(f\"{HOME}/runs/detect/train/R_curve.png\")\n",
        "pr = Image.open(f\"{HOME}/runs/detect/train/PR_curve.png\")\n",
        "f1 = Image.open(f\"{HOME}/runs/detect/train/F1_curve.png\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "axes[0, 0].imshow(p)\n",
        "axes[0, 0].set_title(\"Precision vs Confidence\")\n",
        "axes[0, 0].axis(\"off\")\n",
        "\n",
        "axes[0, 1].imshow(r)\n",
        "axes[0, 1].set_title(\"Recall vs Confidence\")\n",
        "axes[0, 1].axis(\"off\")\n",
        "\n",
        "axes[1, 0].imshow(pr)\n",
        "axes[1, 0].set_title(\"Precision‚ÄìRecall Curve\")\n",
        "axes[1, 0].axis(\"off\")\n",
        "\n",
        "axes[1, 1].imshow(f1)\n",
        "axes[1, 1].set_title(\"F1 Score vs Confidence\")\n",
        "axes[1, 1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zjxKuWWyzu42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Validation: Label Distribution and Bounding Box Correlation\n",
        "\n",
        "Hai bi·ªÉu ƒë·ªì n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng v√† t√≠nh h·ª£p l·ªá c·ªßa dataset tr∆∞·ªõc v√† sau qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh.\n",
        "\n",
        "* **Label Distribution** minh h·ªça ph√¢n b·ªë s·ªë l∆∞·ª£ng m·∫´u v√† k√≠ch th∆∞·ªõc bounding box c·ªßa c√°c l·ªõp trong dataset. Bi·ªÉu ƒë·ªì n√†y gi√∫p ph√°t hi·ªán t√¨nh tr·∫°ng m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu, c√°c l·ªõp c√≥ qu√° √≠t m·∫´u ho·∫∑c s·ª± ch√™nh l·ªách l·ªõn v·ªÅ k√≠ch th∆∞·ªõc ƒë·ªëi t∆∞·ª£ng.\n",
        "\n",
        "* **Bounding Box Correlation** th·ªÉ hi·ªán m·ªëi quan h·ªá gi·ªØa c√°c thu·ªôc t√≠nh h√¨nh h·ªçc c·ªßa bounding box nh∆∞ chi·ªÅu r·ªông, chi·ªÅu cao v√† t·ª∑ l·ªá khung h√¨nh. Ph√¢n t√≠ch n√†y gi√∫p ph√°t hi·ªán c√°c annotation b·∫•t th∆∞·ªùng v√† x√°c nh·∫≠n r·∫±ng dataset bao ph·ªß ƒëa d·∫°ng c√°c k√≠ch th∆∞·ªõc v√† h√¨nh d·∫°ng ƒë·ªëi t∆∞·ª£ng.\n",
        "\n",
        "Vi·ªác tr√¨nh b√†y ƒë·ªìng th·ªùi hai bi·ªÉu ƒë·ªì n√†y nh·∫±m ch·ª©ng minh r·∫±ng dataset ƒë√£ ƒë∆∞·ª£c ki·ªÉm tra v√† x√°c th·ª±c v·ªÅ m·∫∑t ph√¢n b·ªë nh√£n c≈©ng nh∆∞ ƒë·∫∑c t√≠nh h√¨nh h·ªçc, ƒë·∫£m b·∫£o t√≠nh ph√π h·ª£p cho b√†i to√°n ph√°t hi·ªán r·∫Øn v·ªõi ƒë·∫∑c tr∆∞ng ƒë·ªëi t∆∞·ª£ng nh·ªè, d√†i v√† l·∫´n n·ªÅn ph·ª©c t·∫°p."
      ],
      "metadata": {
        "id": "uiT4WxH51PUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "labels = Image.open(f\"{HOME}/runs/detect/train/labels.jpg\")\n",
        "corr = Image.open(f\"{HOME}/runs/detect/train/labels_correlogram.jpg\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "axes[0].imshow(labels)\n",
        "axes[0].set_title(\"Label Distribution\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(corr)\n",
        "axes[1].set_title(\"Bounding Box Correlation\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VqD6mG5C1PvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAObQt4nlKLD"
      },
      "source": [
        "# Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRMVH1pnoXgD"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "model = YOLO(f'{HOME}/runs/detect/train/weights/best.pt')\n",
        "\n",
        "ds = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f\"{DATASET_PATH}/test/images\",\n",
        "    annotations_directory_path=f\"{DATASET_PATH}/test/labels\",\n",
        "    data_yaml_path=DATA_YAML_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S97p_O7YPsa"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "i = random.randint(0, len(ds))\n",
        "\n",
        "image_path, image, target = ds[i]\n",
        "\n",
        "results = model(image, verbose=False)[0]\n",
        "detections = sv.Detections.from_ultralytics(results).with_nms()\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yb269euE1km"
      },
      "source": [
        "# Call t·∫Øt laptop sau khi train xong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H18osLxaE41S"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "WEBHOOK_URL = \"https://forcepslike-lawanda-semicalcined.ngrok-free.dev/done\"  # ƒë·ªïi URL c·ªßa b·∫°n\n",
        "\n",
        "try:\n",
        "    r = requests.post(WEBHOOK_URL)\n",
        "    print(\"ƒê√£ g·ª≠i t√≠n hi·ªáu shutdown v·ªÅ PC!\")\n",
        "except Exception as e:\n",
        "    print(\"Kh√¥ng g·ª≠i ƒë∆∞·ª£c webhook:\", e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}